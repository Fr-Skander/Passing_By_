{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras  \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "\n",
    "model=load_model(r\"C:\\Users\\frigu\\Downloads\\Orange\\IA\\my_model.h5\")\n",
    "results={0:'without mask',1:'mask'}\n",
    "GR_dict={0:(0,0,255),1:(0,255,0)}\n",
    "rect_size = 4\n",
    "cap = cv2.VideoCapture(0) \n",
    "#~/OpenCV/opencv/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "haarcascade =cv2.CascadeClassifier (r'C:\\Users\\frigu\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml')\n",
    "while True:\n",
    "    (rval, im) = cap.read()\n",
    "    im=cv2.flip(im,1,1) \n",
    "    \n",
    "#~/OpenCV/opencv/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "    rerect_size = cv2.resize(im, (im.shape[1] // rect_size, im.shape[0] // rect_size))\n",
    "    cv2.imshow('frame', rerect_size)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "    faces = haarcascade.detectMultiScale(rerect_size,scaleFactor=1.05,minNeighbors=5)#\n",
    "    for f in faces:\n",
    "        (x, y, w, h) = [v * rect_size for v in f] \n",
    "        \n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        rerect_sized=cv2.resize(face_img,(150,150))\n",
    "        normalized=rerect_sized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=model.predict(reshaped)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),GR_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),GR_dict[label],-1)\n",
    "        cv2.putText(im, results[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "    cv2.imshow('LIVE',   im)\n",
    "    key = cv2.waitKey(10)\n",
    "    \n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model=load_model(r\"C:\\Users\\frigu\\Downloads\\Orange\\IA\\my_model.h5\")\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras  \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "\n",
    "model=load_model(r\"C:\\Downloads\\Orange\\IA\\my_model.h5\")\n",
    "results={0:'without mask',1:'mask'}\n",
    "GR_dict={0:(0,0,255),1:(0,255,0)}\n",
    "rect_size = 4\n",
    "im = cv2.imread(r'E:\\image2.jpg') \n",
    "#~/OpenCV/opencv/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "haarcascade =cv2.CascadeClassifier (r'C:\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml')\n",
    "im=cv2.flip(im,1,1) \n",
    "cv2.imshow('LIVE',im)\n",
    "cv2.waitKey(0)\n",
    "    \n",
    "#~/OpenCV/opencv/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "rerect_size = cv2.resize(im, (im.shape[1] // rect_size, im.shape[0] // rect_size))\n",
    "\n",
    "    \n",
    "faces = haarcascade.detectMultiScale(rerect_size,scaleFactor=1.05,minNeighbors=5)#\n",
    "\n",
    "for f in faces:\n",
    "    (x, y, w, h) = [v * rect_size for v in f] \n",
    "        \n",
    "    face_img = im[y:y+h, x:x+w]\n",
    "    rerect_sized=cv2.resize(face_img,(150,150))\n",
    "    normalized=rerect_sized/255.0\n",
    "    reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "    reshaped = np.vstack([reshaped])\n",
    "    result=model.predict(reshaped)\n",
    "        \n",
    "    label=np.argmax(result,axis=1)[0]\n",
    "    print(f\"label : {result}\")\n",
    "      \n",
    "    cv2.rectangle(im,(x,y),(x+w,y+h),GR_dict[label],2)\n",
    "    cv2.rectangle(im,(x,y-40),(x+w,y),GR_dict[label],-1)\n",
    "    cv2.putText(im, results[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "    cv2.imwrite(r'E:\\image_ma8ir mask.jpg',im)\n",
    "    cv2.imshow('LIVE',im)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ai.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tflite_runtime.interpreter as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def Predect():\n",
    "    # create object\n",
    "    #model=tf.keras.Model()\n",
    "    interpreter = tf.Interpreter(r'/home/pi/Desktop/model.tflite')\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    #model=load_model(r\"C:\\Users\\frigu\\Downloads\\Orange\\IA\\my_model.h5\")\n",
    "    results={0:'without mask',1:'mask'}\n",
    "    GR_dict={0:(0,0,255),1:(0,255,0)}\n",
    "    rect_size = 4\n",
    "    im = cv2.imread('/home/pi/Desktop/image.jpg')\n",
    "    #~/OpenCV/opencv/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "    haarcascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\") #Note the change\n",
    "    im=cv2.flip(im,1,1)     \n",
    "    #~/OpenCV/opencv/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "    rerect_size = cv2.resize(im, (im.shape[1] // rect_size, im.shape[0] // rect_size))\n",
    "\n",
    "    faces = haarcascade.detectMultiScale(rerect_size)#\n",
    "    for f in faces:\n",
    "        (x, y, w, h) = [v * rect_size for v in f] \n",
    "          \n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        rerect_sized=cv2.resize(face_img,(150,150))\n",
    "        normalized=rerect_sized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        interpreter.invoke()\n",
    "        \n",
    "        #result=interpreter.predict(reshaped)\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        print(type(output_data))\n",
    "        print(output_data[0][0])\n",
    "        print(\", the output is {}\".format(output_data))    \n",
    "        label=np.argmax(output_data,axis=1)[0]\n",
    "        print(label) \n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),GR_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),GR_dict[label],-1)\n",
    "        print(GR_dict[label])\n",
    "        cv2.putText(im, results[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        cv2.imshow('frame',   im)\n",
    "        cv2.waitKey(0)\n",
    "        return im\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import datetime\n",
    "\n",
    "def DBConnection():\n",
    "    db = mysql.connector.connect(\n",
    "        host=\".....\",\n",
    "        username=\"......\",\n",
    "        password=\"......\",\n",
    "        db=\"....\"\n",
    "    )\n",
    "    return db\n",
    "\n",
    "def get_all_user_ids(curseur, db):\n",
    "    try:\n",
    "        curseur.execute(f\"select id_employee from user\")\n",
    "        users = curseur.fetchall()    \n",
    "        users = [users[l][0] for l in range(len(users)) ] \n",
    "        users = [user.split(\":\") for user in users]\n",
    "        users = [[int(l) for l in user] for user in users]\n",
    "    except:\n",
    "        print('No users ids!!!')\n",
    "    return users\n",
    "\n",
    "def get_all_user_ids(curseur, db):\n",
    "    try:\n",
    "        curseur.execute(f\"select DISTINCT id_employee from user\")\n",
    "        users = curseur.fetchall()    \n",
    "        users = [users[l][0] for l in range(len(users)) ] \n",
    "        users = [user.split(\":\") for user in users]\n",
    "        users = [[int(l) for l in user] for user in users]\n",
    "    except:\n",
    "        print('No users ids!!!')\n",
    "    return users\n",
    "\n",
    "def add_snapshot(user_id, verdict, name=\"Goerge\", email=\"goerge@gmail.com\"):\n",
    "    now = datetime.datetime.now()\n",
    "    # 2010-12-03 16:01:06\n",
    "    now = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    try:\n",
    "        curseur.execute(f\"INSERT INTO `entrance_snapshot`(`id_employee`, `name`, `email`, `time`, `verdict`) VALUES ('{user_id}','{name}','{email}','{now}',{verdict});\")\n",
    "        db.commit()\n",
    "    except:\n",
    "        print('Error')\n",
    "    # print((f\"INSERT INTO `entrance_snapshot`(`id_employee`, `name`, `email`, `time`, `verdict`) VALUES ({user_id},{name},{email},{now},{verdict});\"))\n",
    "    db.commit()\n",
    "\n",
    "\n",
    "\n",
    "# Main\n",
    "db = DBConnection()\n",
    "curseur = db.cursor()\n",
    "# users_ids =  get_all_user_ids(curseur, db)\n",
    "# print(users_ids)\n",
    "# print(type(users_ids))\n",
    "\n",
    "#add_snapshot(\"185:226:95:179:183\", False)\n",
    "\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFID_camera.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RPi.GPIO as GPIO #Importe la bibliothèque pour contrôler les GPIOs\n",
    "from pirc522 import RFID\n",
    "\n",
    "from picamera import PiCamera\n",
    "from time import sleep\n",
    "import cv2\n",
    "from Script import *\n",
    "from ai import *\n",
    "\n",
    "\n",
    "GPIO.setmode(GPIO.BOARD) #Définit le mode de numérotation (Board)\n",
    "GPIO.setwarnings(False) #On désactive les messages d'alerte\n",
    "camera = PiCamera()\n",
    "\n",
    "LED_RED = 3 #Définit le numéro du port GPIO qui alimente la led rouge\n",
    "LED_GREEN = 5 #Définit le numéro du port GPIO qui alimente la led verte\n",
    "\n",
    "test=False\n",
    "rc522 = RFID() #On instancie la lib\n",
    "\n",
    "def turn_led_on (led) :\n",
    "    GPIO.setup(led, GPIO.OUT) #Active le contrôle du GPIO\n",
    "    GPIO.output(led, GPIO.HIGH) #Allume la led\n",
    "\n",
    "#Définit la fonction permettant d'éteindre une led\n",
    "def turn_led_off (led) :\n",
    "    GPIO.setup(led, GPIO.OUT) #Active le contrôle du GPIO\n",
    "    GPIO.output(led, GPIO.LOW) #Eteind la led\n",
    "\n",
    "#Définit la fonction permettant d'allumer la rouge et éteindre la verte\n",
    "def turn_red_on () :\n",
    "    turn_led_off(LED_GREEN) #Eteind la led verte\n",
    "    turn_led_on(LED_RED) #Allume la led rouge\n",
    "\n",
    "#Définit la fonction permettant d'allumer la verte et éteindre la rouge\n",
    "def turn_green_on () :\n",
    "    turn_led_off(LED_RED) #Eteind la led rouge\n",
    "    turn_led_on(LED_GREEN) #Allume la led verte\n",
    "\n",
    "#Définit la fonction permettant d'allumer la rouge et éteindre la verte\n",
    "def Take_Picture() :\n",
    "    camera.start_preview()\n",
    "    sleep(3)\n",
    "    camera.capture('/home/pi/Desktop/image.jpg')\n",
    "    camera.stop_preview()\n",
    "    im='/home/pi/Desktop/image.jpg'\n",
    "    return im\n",
    "\n",
    "\n",
    "\n",
    "print('En attente d\\'un badge (pour quitter, Ctrl + c): ') #On affiche un message demandant à l'utilisateur de passer son badge\n",
    "\n",
    "#On va faire une boucle infinie pour lire en boucle\n",
    "while True :\n",
    "    rc522.wait_for_tag() #On attnd qu'une puce RFID passe à portée\n",
    "    (error, tag_type) = rc522.request() #Quand une puce a été lue, on récupère ses infos\n",
    "\n",
    "    if not error : #Si on a pas d'erreur\n",
    "        (error, uid) = rc522.anticoll() #On nettoie les possibles collisions, ça arrive si plusieurs cartes passent en même temps\n",
    "        if not error : #Si on a réussi à nettoyer\n",
    "            db = DBConnection()\n",
    "            curseur = db.cursor()\n",
    "            users_ids=get_all_user_ids(curseur, db)\n",
    "            \n",
    "            print(f\"Base de données : {users_ids}\")\n",
    "            for RFID_UID in users_ids :\n",
    "                if RFID_UID == uid :\n",
    "                    print('Badge {} autorisé !'.format(uid))\n",
    "                    turn_green_on()\n",
    "                    im=Take_Picture()\n",
    "                    test=True\n",
    "                    GPIO.output(LED_GREEN, GPIO.LOW) #Eteind la led\n",
    "                    #im=Predect(im)\n",
    "                    cv2.imshow('frame',im)\n",
    "                    cv2.waitKey(0)\n",
    "                    break\n",
    "            if not test:\n",
    "                print('Badge {} interdit !'.format(uid))\n",
    "                turn_red_on()\n",
    "\n",
    "        test=False\n",
    "        sleep(2) #On attend 1 seconde pour ne pas lire le tag des centaines de fois en quelques milli-secondes\n",
    "        GPIO.output(LED_GREEN, GPIO.LOW) #Eteind la led\n",
    "        GPIO.output(LED_RED, GPIO.LOW) #Eteind la led\n",
    "        # Main\n",
    "        # users_ids =  get_all_user_ids(curseur, db)\n",
    "        # print(users_ids)\n",
    "        # print(type(users_ids))\n",
    "\n",
    "        #add_snapshot(\"185:226:95:179:183\", False)\n",
    "        db.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef667af2154567c3dd211d12732fdd0b7942a9f383849756b0a2658b1701a9f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
